---
title: "Sequencing 16S rRNA gene fragments using the Pacific Biosciences DNA sequencer"
author: "Patrick D. Schloss"
date: "July 21, 2014"
output: html_document
---

##Pipeline development
We were interested in the ability of PacBio to sequence varying sized regions from the 16S rRNA gene we fragments from the gene using DNA from a defined mock community, feces from a human and mouse, and soil. This notebook provides the mothur code and scripts that we used to process the results of our analysis. 

We ran 10 SMRT cells and their data were located in the following folders that were housed within a folder called `raw_data`:  
<code>  B01_1_Cell2_PacBioRun109_PSchloss311_p15  
	C01_1_Cell3_PacBioRun109_PSchloss315_p16  
	D01_1_Cell4_PacBioRun108_PSchloss310_p13  
	D01_1_Cell4_PacBioRun109_PSchloss316_p4  
	E01_1_Cell5_PacBioRun108_PSchloss311_p15  
	E01_1_Cell5_PacBioRun109_PSchloss317_p19  
	F01_1_Cell6_PacBioRun108_PSchloss312_p35  
    H01_1_Cell8_PacBioRun112_PSchloss319_p19</code>

If you substitute the "\_p" for "\_v" you'll see what region each run represented. There were two V15 runs and two V19 runs. These regions were amplified with the following primer sets:

<code>	V19	AGRGTTTGATYMTGGCTCAG	GGYTACCTTGTTACGACTT  
	V16	AGRGTTTGATYMTGGCTCAG	ACRACACGAGCTGACGAC  
	V15	AGRGTTTGATYMTGGCTCAG	CCCGTCAATTCMTTTRAGT  
	V13	AGRGTTTGATYMTGGCTCAG	ATTACCGCGGCTGCTGG  
	V35	CCTACGGGAGGCAGCAG	CCCGTCAATTCMTTTRAGT  
	V4	 GTGCCAGCMGCCGCGGTAA	GGACTACHVGGGTWTCTAAT</code>

We also put sequencing indices at the 5' and 3' of the inserts to correspond to the different samples:

<code>	mock1	ccaac	ccaac  
	mock2	ggttg	ccaac  
	mock3	ttggt	ccaac  
	mouse1	aggtg	ccaac  
	mouse2	cttac	ccaac  
	mouse3	gaact	ccaac  
	human1	tccga	ccaac  
	human2	acagt	ccaac  
	human3	cactg	ccaac  
	soil1	aacca	ccaac  
	soil2	tgtca	ccaac  
	soil3	aaacc	ccaac</code>


Putting it all together in an oligos file (pacbio.oligos), we get...

<code>	primer	AGRGTTTGATYMTGGCTCAG	GGYTACCTTGTTACGACTT	v19  
	primer	AGRGTTTGATYMTGGCTCAG	ACRACACGAGCTGACGAC	v16  
	primer	AGRGTTTGATYMTGGCTCAG	CCCGTCAATTCMTTTRAGT	v15  
	primer	AGRGTTTGATYMTGGCTCAG	ATTACCGCGGCTGCTGG	v13  
	primer	CCTACGGGAGGCAGCAG	CCCGTCAATTCMTTTRAGT	v35  
	primer	GTGCCAGCMGCCGCGGTAA	GGACTACHVGGGTWTCTAAT	v4  
	barcode	ccaac	ccaac	mock1  
	barcode	ggttg	ccaac	mock2  
	barcode	ttggt	ccaac	mock3  
	barcode	aggtg	ccaac	mouse1  
	barcode	cttac	ccaac	mouse2  
	barcode	gaact	ccaac	mouse3  
	barcode	tccga	ccaac	human1  
	barcode	acagt	ccaac	human2  
	barcode	cactg	ccaac	human3  
	barcode	aacca	ccaac	soil1  
	barcode	tgtca	ccaac	soil2  
	barcode	aaacc	ccaac	soil3</code>

Let's use bash to clean up the folders a bit since these file names are long and unwieldy. We'll start by creating a folder called  `ccs.fastq`. We'll transfrer the fastqs from the `raw_data` folder into into region-specific folders: 


```{r engine='bash'}
  mkdir ccs.fastqs
  cd ccs.fastqs
  mkdir v19 v16 v15 v13 v35 v4
  for REGION in 19 16 15 13 35 4
  do
      cp ../raw_data/*_p$REGION/Analysis_Results/*ccs.fastq v$REGION
  done
  
  ls */*fastq | cut -f 1 -d "/" | sort | uniq -c
```

This last command allows us to see that every region has 3 \*.ccs.fastq files, except for the v15 (6 files) and v19 (4 files) regions. Let's go ahead and concatenate those fastq files and dump them into individual folders.

```{r engine='bash'}
cd ../
mkdir v19 v16 v15 v13 v35 v4

for REGION in $(ls -d v*)
do
    > $REGION/$REGION.fastq
    for FILE in ccs.fastqs/$REGION/*.ccs.fastq
    do
        cat $FILE >> $REGION/$REGION.fastq
    done
done
cd ../
```

We'd also like to concatenate the subread fasta files so that we can see how many base pairs were sequenced for each fragment:

```{r engine='bash'}
mkdir subreads.fasta
cd subreads.fasta

mkdir v19 v16 v15 v13 v35 v4
for REGION in 19 16 15 13 35 4
do
    cp ../raw_data/*_p$REGION/Analysis_Results/*subreads.fasta v$REGION > v$REGION/v$REGION.subreads.fasta

    for FILE in v$REGION/*.subreads.fasta
    do
        cat $FILE >> v$REGION/v$REGION.subreads.fasta
    done
done
```

For each of these subreads fasta files, we'd like to know the number of subreads per sequence as well as the length of the pooled subreads. We can run this with an R script:

```{r}
coverage <- function(folder){
  suffix <- ".subreads.fasta"

	file <- paste(folder, "/", folder, suffix, sep="")
	data <- scan(file, what="", quiet=T)	

	headers <- data[grepl("^>", data)]
	headers <- substr(headers, 2, length(headers))

	id <- gsub(".*/(\\d*)/.*", "\\1", headers)
	start <- as.numeric(gsub(".*/(\\d*)_\\d*", "\\1", headers))
	end <- as.numeric(gsub(".*/\\d*_(\\d*)", "\\1", headers))

	freq <- table(id)
	length <- aggregate(end-start, by=list(id), sum)	

	data <- matrix(rep(NA, 2*length(freq)), ncol=2)
	colnames(data) <- c("freq", "length")
	rownames(data) <- names(freq)
	data[,"freq"] <- freq[]
	data[,"length"] <- length$x
	write.table(data[order(as.numeric(rownames(data))),], file=paste(folder, "/", folder, ".coverage", sep=""), quote=F)
    return(folder)
}

lapply(dir(), coverage)

```

Now we'd like to generate fasta and quality score files for each ccs file. When we do this, it is critical that we set the pacbio parameter to T. This is because by default PacBio will assign a base call even if the quality score is zero:


```{r engine='bash'}
cd ../

for REGION in v*
do
    mothur "#fastq.info(fastq=$REGION/$REGION.fastq, pacbio=T, outputdir=./$REGION/)"
done
```

Using the primer and barcode information from above, we can make region-specific oligos files and put them into the regional folders:

```{r engine='bash'}
for REGION in v*
do
    grep ""$REGION"" pacbio.oligos > $REGION/$REGION.oligos
    grep "barcode" pacbio.oligos >> $REGION/$REGION.oligos
done
```

Now we're all set to run some mothur commands. Since each file is a mixture of our mock community and data from soil, human feces, and mouse feces, we need to split the fasta and qual files by barcode. Let's initially be generous and allow for 2 mismatches to each barcode and 4 mismatches to each primer. To keep things simple, we'll concatenate the three mock community fasta, quality score, and groups files. We modified the source code to output the total number of mismatches to the barcodes and primers on the header line for each sequence in the trim file.

```{r engine='bash'}
for REGION in v*
do
    cd $REGION
    mothur "#trim.seqs(fasta=$REGION.fasta, qfile=$REGION.qual, oligos=$REGION.oligos, checkorient=T, pdiffs=6, bdiffs=4, allfiles=T, processors=8)"
    cat $REGION*mock?.$REGION.fasta > $REGION.mock.fasta
    cat $REGION*mock?.$REGION.qual > $REGION.mock.qual
    cat $REGION*mock?.$REGION.groups > $REGION.mock.groups
    grep ">" $REGION.mock.fasta > $REGION.mismatches
    cd ../
done
```

Let's go back and extract the coverage data for each of the sequences using another R script:

```{r}
getCoverage <- function(region){
  write(region, "")
	file <- paste(region, "/", list.files(region, pattern="v\\d*.mock?.fasta"), sep="")
	fasta <- scan(file, what="", quiet=T)
	seqNames <- fasta[grepl(">", fasta)]
	seqNames <- gsub(".*/(\\d*)/.*", "\\1", seqNames)

	coverage <- read.table(file=paste("subreads.fasta/", region, "/", region, ".coverage", sep=""), header=T)
	mock.coverage <- coverage[(seqNames),]
	
	write.table(mock.coverage, file=paste(region, "/", region, ".ccs.coverage", sep=""))
}


lapply(dir("./", pattern="v\\d*"), getCoverage)
```

Let's also calculate the average quality score for all of the trimmed sequences as well as the minimum average quality score over a 50 bp window:

```{r}
getAverageScore <- function(scoreString){
  scoreVector <- as.numeric(unlist(strsplit(scoreString, " ")))
    scoreVector[scoreVector > 72] <- 72
	return(mean(scoreVector))
}

getMinRollingAverage <- function(scoreString, windowSize){
	scoreVector <- as.numeric(unlist(strsplit(scoreString, " ")))
    scoreVector[scoreVector > 72] <- 72
    min.avg <- 0
    
    if(length(scoreVector) > windowSize){
        avg <- filter(scoreVector, rep(1/windowSize, windowSize), side=1)
        min.avg <- min(avg, na.rm=T)
    }
	return(min.avg)
}

reportAverageScores <- function(folder, windowSize = 50){
	write(folder, "")
	qual <- scan(file=paste(folder, "/", folder, ".mock.qual", sep=""), what="", sep="\n", quiet=T)
	seq.names <- qual[1:length(qual) %% 2 == 1]
	seq.names <- gsub(".*/(\\d*)/.*", "\\1", seq.names)
	seq.scores <- qual[1:length(qual) %% 2 == 0]

	ave.scores <- unlist(lapply(seq.scores, getAverageScore))
	min.scores <- unlist(lapply(seq.scores, getMinRollingAverage, windowSize))
	
	report <- cbind(ave.scores, min.scores)
	rownames(report) <- seq.names
	colnames(report) <- c("ave", "min")
	
	write.table(report, paste(folder, "/", folder, ".mock.qreport", sep=""), quote=F)
}

lapply(dir("./", pattern="v\\d*"), reportAverageScores)
```

We are now ready to calculate the error rate for the various regions using the mock community and the HMP_MOCK sequence data. We will use mothur to align the sequences to HMP_MOCK.align, determine the start and end positions of the alignment, and calculate the error rate.

```{r engine='bash'}
for REGION in v*
do
    mothur "#align.seqs(fasta=$REGION/$REGION.mock.fasta, reference=HMP_MOCK.align, processors=8, outputdir=./$REGION/);
        filter.seqs(fasta=$REGION/$REGION.mock.align-HMP_MOCK.align, vertical=T);
        summary.seqs();
        seq.error(fasta=$REGION/$REGION.mock.filter.fasta, reference=$REGION/HMP_MOCK.filter.fasta, report=$REGION/$REGION.mock.align.report, qfile=$REGION/$REGION.mock.qual, processors=8);"
done
```

We now have all of the data summaries we need to start looking at the relationship between different factors and the sequencing error rates. We begin by looking at the different types of errors in our data.

```{r}
regions <- dir("./", pattern="v.*")

sub.matrix <- read.table(file=paste(regions[1], "/", regions[1], ".mock.filter.error.matrix", sep=""), header=T, row.names=1)[-7,]
for(i in 2:length(regions)){
  sub.matrix <- sub.matrix + read.table(file=paste(regions[i], "/", regions[i], ".mock.filter.error.matrix", sep=""), header=T, row.names=1)[-7,]
}

matches <- c(sub.matrix[1,1], sub.matrix[2,2], sub.matrix[3,3], sub.matrix[4,4])
total <- sum(sub.matrix)
errors <- sub.matrix
diag(errors[1:4,1:4]) <- 0
error.rate <- 100 * sum(errors) / total				#1.925717

subst.bias <- apply(errors[1:4,1:4], 2, sum)/apply(sub.matrix[1:4,1:4], 2, sum)
subst.bias/sum(subst.bias)
#       rA        rT        rG        rC 
#0.2247412 0.2748158 0.2392554 0.2611875 
#these are more or less equal to each other

insert.bias <- (sub.matrix[,"rGap"]/apply(sub.matrix, 1, sum))[1:4]
insert.bias/sum(insert.bias)
#       qA        qT        qG        qC 
#0.2364246 0.2432987 0.2425315 0.2777452 
#these are more or less equal to each other

delete.bias <- (sub.matrix["qGap",]/apply(sub.matrix, 2, sum))[1:4]
delete.bias/sum(delete.bias)
#            rA        rT       rG        rC
#qGap 0.1167635 0.0978054 0.442078 0.3433531
#interestingly the G's and C's are more likely to be deleted than the As or Ts

substitutions <- sum(errors[1:4,1:4])/sum(errors)	#0.3656617
insertions <- sum(errors[,5])/sum(errors)			#0.450299
deletions <- sum(errors[5,])/sum(errors)			#0.167206
ambiguous <- sum(errors[6,])/sum(errors)			#0.02157014
```

These results indicate that that the overall error rate is 1.93%. Of this error, 36.5% is from substitutions, 45% is from insertions, 16.7% is from deletions, and 2.2% is from ambiguous base calls. There does not appear to be a base bias for subustitutions or insertions; however, there is a tendency towards deleting G's and C's.

Let's look to see whether there are any associations between the type of error and the quality score.

```{r}
regions <- dir("./", pattern="v.*")

error.quality <- read.table(file=paste(regions[1], "/", regions[1], ".mock.filter.error.quality", sep=""), header=T, row.names=1)[-7,]
for(i in 2:length(regions)){
  error.quality <- error.quality + read.table(file=paste(regions[i], "/", regions[i], ".mock.filter.error.quality", sep=""), header=T, row.names=1)[-7,]
}
error.quality["72",] <- error.quality["72",] + error.quality["80",]
error.quality <- error.quality[1:72,]

#make own boxplot

matches <- rep(as.numeric(rownames(error.quality)), error.quality$matches)
m.quant <- quantile(matches, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

subs <- rep(as.numeric(rownames(error.quality)), error.quality$substitutions)
s.quant <- quantile(subs, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

ins <- rep(as.numeric(rownames(error.quality)), error.quality$insertions)
i.quant <- quantile(ins, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

ambig <- rep(as.numeric(rownames(error.quality)), error.quality$ambiguous)
a.quant <- quantile(ambig, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))


par(mar=c(6, 5, 0.5, 0.5))
plot(1, xlim=c(0.5, 4.5), ylim=c(0,80), type="n", yaxt="n", xaxt="n", xlab="", ylab="")
polygon(x=c(0.75, 1.25, 1.25, 0.75), y=c(m.quant["25%"], m.quant["25%"], m.quant["75%"], m.quant["75%"]))
polygon(x=c(1.75, 2.25, 2.25, 1.75), y=c(s.quant["25%"], s.quant["25%"], s.quant["75%"], s.quant["75%"]))
polygon(x=c(2.75, 3.25, 3.25, 2.75), y=c(i.quant["25%"], i.quant["25%"], i.quant["75%"], i.quant["75%"]))
polygon(x=c(3.75, 4.25, 4.25, 3.75), y=c(a.quant["25%"], a.quant["25%"], a.quant["75%"], a.quant["75%"]))
segments(x0=seq(0.75, 3.75, 1), x1=seq(1.25,4.25,1), y0=c(m.quant["50%"], s.quant["50%"], i.quant["50%"], a.quant["50%"]), lwd=4)

arrows(x0=1:4, y0=c(m.quant["75%"], s.quant["75%"], i.quant["75%"], a.quant["75%"]), y1=c(m.quant["97.5%"], s.quant["97.5%"], i.quant["97.5%"], a.quant["97.5%"]), angle=90)
arrows(x0=1:4, y0=c(m.quant["25%"], s.quant["25%"], i.quant["25%"], a.quant["25%"]), y1=c(m.quant["2.5%"], s.quant["2.5%"], i.quant["2.5%"], a.quant["2.5%"]), angle=90)

axis(2, las=2)
axis(1, at=c(1,2,3,4), label=c("Matches", "Substitutions", "Insertions", "Deletions"), las=2)
title(ylab="Quality score")
```

There is a pretty good separtion between the correct and incorrect (substitutions/insertions) base calls. We will use this later to help us develop a plan for screening out sequences that are of low quality.  
  
Let's start by establishing a basic curation method. Let's remove any sequences with a homopolymer length longer than 8, sequences with ambiguous base calls, sequences that don't start and end at the expected positions, and any sequences that were flagged as being chimeras (these aren't sequencing errors).

```{r}
getMode <- function(x){
  return(as.numeric(names(sort(table(x), decreasing=T)[1])))
}

generateComposite <- function(folder){
	write(folder, "")

  #read everything in
	coverage <- read.table(file=paste(folder, "/", folder, ".ccs.coverage", sep=""), header=T, row.names=1)
	mismatches <- read.table(file=paste(folder, "/", folder, ".mismatches", sep=""), header=F, row.names=1)
	aveq <- read.table(file=paste(folder, "/", folder, ".mock.qreport", sep=""), header=F, skip=1)
	error <- read.table(file=paste(folder, "/", folder, ".mock.filter.error.summary", sep=""), header=T, row.names=1)
	summary <- read.table(file=paste(folder, "/", folder, ".mock.filter.summary", sep=""), header=T, row.names=1)

  #remove chimeras
	non.chimeras <- error$numparents==1

  coverage <- coverage[non.chimeras,]
  mismatches <- mismatches[non.chimeras,]
  aveq <- aveq[non.chimeras,]
  error <- error[non.chimeras,]
  summary <- summary[non.chimeras,]
  
	#fix some column names
	colnames(mismatches) <- c("barcode", "primer")
    aveq <- aveq[,-1]
    colnames(aveq) <- c("aveQ", "minQ")
    

	mode.start <- getMode(summary$start)
	mode.end <- getMode(summary$end)

    good.start <- summary$start == mode.start  #find sequences that start at correct location in alignment
    good.end <- summary$end == mode.end        #find sequences that end at correct location in alignment
	good.homop <- summary$polymer <= 8         #find sequences with less than or equal to 8 nt
    good.ambig <- summary$ambig == 0           #find sequences with no ambiguous base calls
    
	good.sequences <- good.start & good.end & good.homop & good.ambig


	#create composite data frame of good sequences
	composite <- cbind(error[good.sequences,], coverage[good.sequences,],
						mismatches[good.sequences,], aveq[good.sequences,],
						summary[good.sequences,])
	write.table(composite, paste(folder, "/", folder, ".composite", sep=""), quote=F, sep="\t")
  
  n.seqs <- nrow(summary)
  lost.start.stop <- 1- sum(good.start & good.end)/n.seqs
  lost.homop <- 1 - sum(good.homop)/n.seqs
  lost.ambig <- 1 - sum(good.ambig)/n.seqs
  lost.total <- 1 - sum(good.sequences)/n.seqs
  
  return(c(lost.start.stop, lost.homop, lost.ambig, lost.total))
}

getInitError <- function(folder){
  error <- read.table(file=paste(folder, "/", folder, ".mock.filter.error.summary", sep=""), header=T, row.names=1)
  error <- error[error$numparents==1,]
  return(c(sum(error$mismatches), sum(error$total)))
}

getBasicError <- function(folder){
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  return(c(sum(composite$mismatches), sum(composite$total)))
}

regions <- dir("./", pattern="^v\\d*")
fraction.lost <- matrix(unlist(lapply(regions, generateComposite)), ncol=4, byrow=T)
rownames(fraction.lost) <- regions
colnames(fraction.lost) <- c("start.stop", "homop", "ambig", "total")
fraction.lost

#    start.stop        homop      ambig      total
#v4  0.03205128 0.0006275776 0.01739286 0.04410974
#v13 0.10845623 0.0005600149 0.08381557 0.17304461
#v35 0.16210726 0.0018959913 0.11565547 0.23469664
#v15 0.12101535 0.0025580480 0.13183786 0.21979536
#v16 0.12669288 0.0008737440 0.20008737 0.28877239
#v19 0.18291262 0.0048543689 0.18485437 0.33145631


init.error <- matrix(unlist(lapply(regions, getInitError)), ncol=2, byrow=T)
rownames(init.error) <- regions
colnames(init.error) <- c("mismatches", "total")
init.rates <- init.error[,"mismatches"] / init.error[,"total"]
init.rates
#        v13         v15         v16         v19         v35          v4 
#0.023997519 0.018050725 0.025606045 0.022916201 0.025057346 0.008257847 


total.init.error <- sum(init.error[,"mismatches"])/sum(init.error[,"total"])
#[1] 0.01925717


basic.error <- matrix(unlist(lapply(regions, getBasicError)), ncol=2, byrow=T)
rownames(basic.error) <- regions
colnames(basic.error) <- c("mismatches", "total")
basic.rates <- basic.error[,"mismatches"] / basic.error[,"total"]
basic.rates
#        v13         v16         v35         v19         v15          v4 
#0.015089630 0.009483316 0.014764301 0.013538793 0.014237063 0.005832224 


total.basic.error <- sum(basic.error[,"mismatches"])/sum(basic.error[,"total"])
#[1] 0.01079351

```

This analysis shows us several things. First, the number of non-chimeric reads removed with this basic filter increases with the length of the region being considered. Most reads are removed because of the presence of ambiguous base calls or failing to span the entire region being amplified and sequenced. Second, with our basic pipeline we reduced the overall error rate effectively in half - 1.93 to 1.08%. The error rate of each region was reduced by ~30 to 50% without a clear trend with fragment length. Our task is to now continue to reduce the error rates of these regions by more than 10-fold to match previous results obtained using 454 and MiSeq.


Because PacBio sequencing is done in a circular manner to produce a conensus sequences, there should be no length effects. Therefore, it stands to reason that the error rate we see in the barcodes and primers, should be the error rate for the entire fragment. If a read has no errors in the barcodes and primers, then we would expect there to be very few errors in the rest of the fragment. If there are a lot of errors, well then we expect a high error rate for the fragment. First, let's plot the error rate for different numbers of mismatches to the barcodes and primers:

```{r}
plotBarcodePrimerError <- function(folder){

  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  
  total.mismatch <- composite$barcode + composite$primer
       
  error.mismatch <- aggregate(composite$error, by=list(total.mismatch), function(x){c(quantile(x, probs=c(0.025, 0.5, 0.975)), length(x))})$x
	colnames(error.mismatch) <- c("lci", "median", "uci", "n")
	rownames(error.mismatch) <- 0:(nrow(error.mismatch)-1)
	error.mismatch[, "n"] <- 100 * error.mismatch[, "n"]/sum(error.mismatch[, "n"])

	par(mar=c(5, 5, 0.5, 0.5))
	stripchart(composite$error~total.mismatch, vertical=T, method="jitter", pch=19, col="grey", ylab="", yaxt="n", ylim=c(0,0.33))
	segments(x0=(1:nrow(error.mismatch))-0.25, x1=(1:nrow(error.mismatch))+0.25, y0=error.mismatch[,"median"], lwd=3)
	segments(x0=(1:nrow(error.mismatch))-0.25, x1=(1:nrow(error.mismatch))+0.25, y0=error.mismatch[,"lci"], lwd=1)
	segments(x0=(1:nrow(error.mismatch))-0.25, x1=(1:nrow(error.mismatch))+0.25, y0=error.mismatch[,"uci"], lwd=1)

	title(xlab="Total number of mismatches to\nbarcodes and primers", ylab="Error rate (%)")
	axis(2, at=seq(0, 0.4, 0.1), label=seq(0,40,10), las=2)
	mtext(1, at=seq(1:nrow(error.mismatch)), text=format(error.mismatch[,"n"], digits=1), line=-1, cex=0.5)
	text(x=1:nrow(error.mismatch), y=error.mismatch[,"median"], label=format(100*error.mismatch[,"median"], digits=2), pos=3, cex=0.8, font=2)
	text(1, 0.33, label=toupper(folder), font=2, cex=1.25)
}

pdf(file="oligo.error.pdf", height=10, width=8)
par(mfrow=c(3,2))
lapply(c("v4", "v35", "v13", "v15", "v16", "v19"), plotBarcodePrimerError)
par(mfrow=c(1,1))
dev.off()

```

We see that the median error rate does increase with the number of mismatches to the barcodes and primers. Considering the total length of the barcodes and primers does not vary much across the regions, there does't seem to be a consistent association between the error rate of the fragment and the oligos. Let's check it out.

```{r}
getFragment_BPErrorRates <- function(folder, length){
  bp.length <- length[folder]
  
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  
	bc.primer <- composite$barcode + composite$primer
  return(cbind(composite$error, bc.primer/bp.length))
}

oligos.file <- scan("../pacbio.oligos", what="", sep="\n", quiet=T)
primers <- oligos.file[grepl("primer", oligos.file)]
region <- gsub(".*(v\\d*)$", "\\1", primers)
length <- nchar(gsub("primer\t(.*)\t(.*)\t.*", "\\1\\2", primers))+10
names(length) <- region

regions <- dir("./", pattern="^v.*")
errors <- lapply(regions, getFragment_BPErrorRates, length)

errors.table <- matrix(errors[[1]], ncol=2, byrow=F)
for(r in 2:length(length)){
  errors.table <- rbind(errors.table, matrix(errors[[r]], ncol=2, byrow=F))
}
colnames(errors.table) <- c("fragment", "oligos")

cor.test(errors.table[, "fragment"], errors.table[,"oligos"])

#  Pearson's product-moment correlation
#
#data:  errors.table[, "fragment"] and errors.table[, "oligos"]
#t = 87.4716, df = 48369, p-value < 2.2e-16
#alternative hypothesis: true correlation is not equal to 0
#95 percent confidence interval:
# 0.3618482 0.3772373
#sample estimates:
#      cor 
#0.3695681 



summary(errors.table)
#    fragment            oligos       
# Min.   :0.000000   Min.   :0.00000  
# 1st Qu.:0.000000   1st Qu.:0.00000  
# Median :0.002242   Median :0.00000  
# Mean   :0.009275   Mean   :0.01388  
# 3rd Qu.:0.009629   3rd Qu.:0.02041  
# Max.   :0.316430   Max.   :0.21277  


```

The last two commands shows us that there is a significant correlation between the barcode/primer error rate and the error rate of the rest of the fragment (R=0.37; P<<0.001) and that the average error rates are comparable. Based on this result, it is clear that we want to minimize the number of mismatches to the barcodes and primers.


A significant factor in PacBio's consensus sequencing is that repeated rounds of sequencing builds one's confidence in the overall base calls. Using the subread data we have already calcualted the coverage as well as the total length sequenced. We will now assess the error rate as a function of the sequence coverage and the number of bases sequenced. The results should be pretty similar so we'll focus primarily on the level of coverage.

```{r}

#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

plotLines <- function(folder){
  write(folder, "")
  
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  
	error.by.depth <- aggregate(composite$error, by=list(composite$freq), function(x){c(mean=mean(x), quantile(x, prob=c(0.025, 0.975)), n=length(x))})

  error.by.depth <- error.by.depth[error.by.depth$x[,"n"]>=50,] #exclude any coverage values where we don't have at least 50 observations
  fold.coverage <- error.by.depth[, "Group.1"]
	error.by.depth <- error.by.depth$x
  
	mean <- error.by.depth[,"mean"]
#	lci <- error.by.depth[,"2.5%"]
#	uci <- error.by.depth[,"97.5%"]
#	N <- error.by.depth[, "n"]
#	percent.n <- N/cumsum(N)
	points(mean~fold.coverage, type="l", lwd=2, col=clrs[folder])
}

pdf("coverageError.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(0,60), ylim=c(0,0.05), type="n", xlab="", ylab="", yaxt="n")
title(xlab="Coverage", ylab="Error rate (%)")
axis(2, at=seq(0,0.05, 0.01), label=seq(0,5, 1), las=2)
lapply(regions, plotLines)
legend(x=40, y=0.05, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()

```

This plot shows us that the error rates appear to plateau around 10-fold coverage. It is interesting that beyond that, the error rate really doesn't improve much. Let's find out the actual average error rate for each region when we only use reads with more than 10-fold coverage:

```{r}

errorAtCoverageCutoff <- function(folder){
  write(folder, "")
  
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  
  total.seqs <- nrow(composite)
	orig.error <- sum(composite$mismatches)/sum(composite$total)
	
  deep <- composite$freq >= 10
	composite <- composite[deep,]

  covered.seqs <- nrow(composite)

	error <- sum(composite$mismatches)/sum(composite$total)
	frac.kept <- covered.seqs / total.seqs
	return(c(orig.error=orig.error, error=error, kept=frac.kept))
}

regions <- dir("./", pattern="v\\d.*")
output <- unlist(lapply(regions, errorAtCoverageCutoff))
output <- matrix(output, ncol=3, byrow=T)
rownames(output) <- regions
colnames(output) <- c("orig", "final", "kept")

o <- order(output[,"orig"])
output[o,]

#           orig       final      kept
#v4  0.005832224 0.002812434 0.7875164
#v15 0.009483316 0.006928824 0.6698613
#v19 0.013538793 0.009889442 0.5620099
#v35 0.014237063 0.010492018 0.6627146
#v16 0.014764301 0.010906203 0.4606880
#v13 0.015089630 0.010385450 0.6568849


error.reduction <- (1-sort(output[,"final"]/output[,"orig"]))*100
error.reduction

#      v4      v13      v19      v15      v35      v16 
#51.77766 31.17492 26.95477 26.93670 26.30490 26.13126 


```

From this we see that there really is no clear pattern between the length of the region and the error rate or the fraction of sequences that we kept. The reduction in error rate varied between 26.2 (V16) and 51.7% (V4).


Next we'll consider the relationship between the sequencing error rate and the average quality score for the read. This should be proportional to the level of coverage. We'll plot the minimum average quality score from the 50-nt sliding window analysis we did above.

```{r}
#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

errorMinQualityScore <- function(folder){
  write(folder, "")

  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  binned <- aggregate(composite$error, by=list(round(composite$minQ)), mean)
  binned <- binned[binned$Group.1 <= 70, ]
  points(binned$Group.1, binned$x, type="l", col=clrs[folder], lwd=2)
}

pdf(file="ErrorMinQ.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.10), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, errorMinQualityScore)
title(xlab="Minimum average quality score\nwithin a 50-nt window across the full sequence", ylab="Error Rate (%)")
axis(2, las=2, at=seq(0,0.1,0.02), label=seq(0,10,2))
legend(x=60, y=0.10, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()

```

Great - as we increase the threshold, we decrease the error rate. The next question is what to pick as our threshold. Let's see how the fraction of reads remaining changes as we increase the threshold:

```{r}

#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

fractionMinQualityScore <- function(folder){
  write(folder, "")

  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
  binned <- aggregate(composite$error, by=list(round(composite$minQ)), length)

  remaining <- 1-cumsum(binned$x)/sum(binned$x)
  points(binned$Group.1, remaining, type="l", col=clrs[folder], lwd=2)
}

pdf(file="fractionMinQ.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,1), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, fractionMinQualityScore)
title(xlab="Minimum average quality score\nwithin a 50-nt window across the full sequence", ylab="Sequences above threshold (%)")
axis(2, las=2, at=seq(0,1,0.2), label=seq(0,100,20))
legend(x=10, y=0.30, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()

```

From this it was difficult to pinpoint a threshold minimum average quality score based on the error rates alone. Let's look at the aggregate error rate for the sequences above the threshold quality score of interest:

```{r}
#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

aggregateErrorMinQualityScore <- function(folder){
  write(folder, "")
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  
  remaining.error <- rep(0, max(composite$minQ)+1)
  qscores <- 0:max(composite$minQ)

  remaining.error <- unlist(lapply(qscores, function(x){mean(composite[composite$minQ >= x,"error"])}))
  names(remaining.error) <- qscores
  
  points(x=10:70, remaining.error[10:70], type="l", col=clrs[folder], lwd=2)
}

pdf(file="remainingErrorMin.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.02), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, aggregateErrorMinQualityScore)
title(xlab="Minimum average quality score\nwithin 50-nt windows from across the full sequence", ylab="Error rate of sequences above threshold (%)")
axis(2, las=2, at=seq(0,0.02,0.005), label=seq(0,2,0.5))
legend(x=55, y=0.02, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()
```

Again, there's no clear break point. Let's try calculating the average quality score for the entire read instead...

```{r}
#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

errorAveQualityScore <- function(folder){
  write(folder, "")
  
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  binned <- aggregate(composite$error, by=list(round(composite$aveQ)), mean)
  binned <- binned[binned$Group.1 <= 70, ]
  points(binned$Group.1, binned$x, type="l", col=clrs[folder], lwd=2)
}

pdf(file="ErrorAveQ.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.10), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, errorAveQualityScore)
title(xlab="Average quality score", ylab="Error Rate (%)")
axis(2, las=2, at=seq(0,0.1,0.02), label=seq(0,10,2))
legend(x=60, y=0.10, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()
```

Great - again, as we increase the threshold, we decrease the error rate. Let's see how the fraction of reads remaining changes as we increase the threshold:

```{r}

#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

fractionAveQualityScore <- function(folder){
  write(folder, "")

  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  binned <- aggregate(composite$error, by=list(round(composite$aveQ)), length)

  remaining <- 1-cumsum(binned$x)/sum(binned$x)
  points(binned$Group.1, remaining, type="l", col=clrs[folder], lwd=2)
}

pdf(file="fractionAveQ.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,1), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, fractionAveQualityScore)
title(xlab="Average quality score", ylab="Sequences above threshold (%)")
axis(2, las=2, at=seq(0,1,0.2), label=seq(0,100,20))
legend(x=10, y=0.30, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()

```

The distribution here looks a little tighter across the different regions with something of an inflection around 60%, which corresponds to an average quality score of 55 to 65 for the regions (except for V4 and V1-V9). Let's see what the error rate is for reads with an average quality score above our thersholds:

```{r}

#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions

aggregateErrorAveQualityScore <- function(folder){
  write(folder, "")
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  
  remaining.error <- rep(0, max(composite$aveQ)+1)
  qscores <- 0:max(composite$aveQ)

  remaining.error <- unlist(lapply(qscores, function(x){mean(composite[composite$aveQ >= x,"error"])}))
  names(remaining.error) <- qscores
  
  points(x=10:70, remaining.error[10:70], type="l", col=clrs[folder], lwd=2)
}

pdf(file="remainingErrorAve.pdf")
par(mar=c(5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.02), type="n", yaxt="n", xlab="", ylab="")
lapply(regions, aggregateErrorAveQualityScore)
title(xlab="Average quality score\nacross the full sequence", ylab="Error rate of sequences above threshold (%)")
axis(2, las=2, at=seq(0,0.02,0.005), label=seq(0,2,0.5))
legend(x=55, y=0.02, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
dev.off()
```

Interestingly, we see that the error rates begin to decline significantly as we increase the threshold past 60. This also corresponds to the steep reduction in the number of remaining reads. Let's propose we use an average quality score threshold of 60 since it produces the most consistent fraction of reads retained and error rate across the different regions. If we do this we get the following error rates:

```{r}

#regions <- dir("./", pattern="v\\d.*")
regions <- c("v4", "v13", "v35", "v15", "v16", "v19")

getErrorRateFromAveQ <- function(folder, threshold=60){
  write(folder, "")
  composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

  rates <- composite[composite$aveQ >= threshold,]
  
  original.error <- mean(composite[,"error"])
  remaining.error <- mean(rates[,"error"])
  fraction.kept <- nrow(rates)/nrow(composite)

  return(c(original.error, remaining.error, fraction.kept))
}

results <- matrix(unlist(lapply(regions, getErrorRateFromAveQ)), ncol=3, byrow=T)
rownames(results) <- regions
colnames(results) <- c("original.error", "remaining.error", "fraction.kept")

#    original.error remaining.error fraction.kept
#v4     0.005741810     0.002923691     0.8667229
#v13    0.014883360     0.009899221     0.7571106
#v35    0.013968573     0.009427016     0.7676517
#v15    0.009367667     0.004816332     0.6967633
#v16    0.014569803     0.009527474     0.6560197
#v19    0.013413156     0.005936197     0.4978217
```

Here we see that we have reduced the error rate by 56 to 75% when we require the average quality score for the read to be at least 60. In addition, we notice that the fraction of the reads we keep decreases as we increase the length of the fragment.  
  
At this point we are kind of out of tricks to reduce the error rate further beyond combining methods. Let's go back and merge our approaches - allow no or one mismatch to the barcodes and primers, require 10-fold coverage, and an average quality score of 60. We are also interested in whether any of these specification are redundant with each other.

```{r}

oligosCoverage <- function(folder){
  write(folder, "")
	composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	
	mismatch <- composite$barcode + composite$primer
	good0 <- mismatch == 0 & composite$freq >= 10
	composite.good0 <- composite[good0,]

	good1 <- mismatch <= 1 & composite$freq >= 10
	composite.good1 <- composite[good1,]

	return(c(mean(composite[,"error"]), mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite), 
										mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
	
}

regions <- dir("./", pattern="^v.*")
oligos.coverage <- matrix(unlist(lapply(regions, oligosCoverage)), ncol=5, byrow=T)
rownames(oligos.coverage) <- regions
colnames(oligos.coverage) <- c("original", "0.error", "0.frac", "1.error", "1.frac")
oligos.coverage
#       original     0.error    0.frac     1.error    1.frac
#v13 0.014883360 0.009371691 0.4302483 0.009899256 0.6108352
#v15 0.009367667 0.004050098 0.3762085 0.005253236 0.5834384
#v16 0.014569803 0.007945951 0.2929975 0.008956478 0.4256757
#v19 0.013413156 0.006706336 0.3142608 0.007903900 0.4856230
#v35 0.013968573 0.009096211 0.4857547 0.009503092 0.6257300
#v4  0.005741810 0.001565052 0.5476458 0.002068184 0.7389796



oligosQScore <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

	mismatch <- composite$barcode + composite$primer
	good <- mismatch == 0 & composite$aveQ>= 60
	composite.good0 <- composite[good,]

	good1 <- mismatch <= 1 & composite$aveQ >= 60
	composite.good1 <- composite[good1,]

	return(c(mean(composite[,"error"]), mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite), 
										mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
}

regions <- dir("./", pattern="^v.*")
oligos.qscore <- matrix(unlist(lapply(regions, oligosQScore)), ncol=5, byrow=T)
rownames(oligos.qscore) <- regions
colnames(oligos.qscore) <- c("original", "0.error", "0.frac", "1.error", "1.frac")
oligos.qscore
#       original     0.error    0.frac     1.error    1.frac
#v13 0.014883360 0.009153895 0.4954853 0.009700915 0.7024831
#v15 0.009367667 0.003217812 0.4057167 0.003993206 0.6213535
#v16 0.014569803 0.007589961 0.4072482 0.008358922 0.6038084
#v19 0.013413156 0.004870705 0.3162939 0.005294429 0.4586117
#v35 0.013968573 0.008365403 0.5501681 0.008690839 0.7207574
#v4  0.005741810 0.001715135 0.5916338 0.002215499 0.8096980


coverageQScore <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

	good <- composite$freq >= 10 & composite$aveQ>= 60
	composite.good <- composite[good,]

	return(c(mean(composite[,"error"]), mean(composite.good[,"error"]), nrow(composite.good)/nrow(composite) ))

}

regions <- dir("./", pattern="^v.*")
coverage.qscore <- matrix(unlist(lapply(regions, coverageQScore)), ncol=3, byrow=T)
rownames(coverage.qscore) <- regions
colnames(coverage.qscore) <- c("original", "error", "frac")
coverage.qscore
#       original       error      frac
#v13 0.014883360 0.010013647 0.6514673
#v15 0.009367667 0.004775956 0.5793190
#v16 0.014569803 0.010487021 0.4588452
#v19 0.013413156 0.005815805 0.3860006
#v35 0.013968573 0.009707464 0.6549283
#v4  0.005741810 0.002636544 0.7850778



allFilters <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste(folder, "/", folder, ".composite", sep=""), header=T, row.names=1)

	mismatch <- composite$barcode + composite$primer
	good0 <- mismatch == 0 & composite$aveQ>= 60 & composite$freq >= 10
	composite.good0 <- composite[good0,]

	good1 <- mismatch <= 1 & composite$aveQ >= 60 & composite$freq >= 10
	composite.good1 <- composite[good1,]

	return(c(mean(composite[,"error"]), mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite), 
										mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))

}

regions <- dir("./", pattern="^v.*")
all.filters <- matrix(unlist(lapply(regions, allFilters)), ncol=5, byrow=T)
rownames(all.filters) <- regions
colnames(all.filters) <- c("original", "0.error", "0.frac", "1.error", "1.frac")
all.filters

#       original     0.error    0.frac     1.error    1.frac
#v13 0.014883360 0.009299146 0.4286682 0.009827404 0.6083521
#v15 0.009367667 0.003078476 0.3450189 0.003905562 0.5210593
#v16 0.014569803 0.007738039 0.2923833 0.008814923 0.4250614
#v19 0.013413156 0.004797594 0.2460064 0.005266467 0.3578275
#v35 0.013968573 0.008613200 0.4813307 0.008979207 0.6190055
#v4  0.005741810 0.001515500 0.5470831 0.001993325 0.7376665

```

When we take a look at the output from oligos.qscore, oligos.coverage, coverage.qscore, and all.filters it becomes apparent that the oligos.qscore strategy reduces the error rates the most, while having a comparable effect on the number of sequences passing the filter relative to the other methods. When we look at the choice of allowing either no or one difference to the oligos, we find a negligible difference between the error rates of the two options. However, we retain considerably more sequences by allowing a single mismatch to the oligos. So, in the end our strategy to reduce the sequencing error rate is to allow a total of one mismatch to the barcodes and primers and using the average quality score threshold of 60.
 
 
Having settled in on a pipeline, we would now like to run that protocol from the beginning on all of our samples. Let's create some new folders and make links to the original fasta files:

```{r engine='bash'}

mkdir pipeline_dev analysis
mv v* pipeline_dev

cd ../analysis
mkdir v13  v15  v16  v19  v35  v4
cd ../pipeline_dev

for REGION in v*
do
    cp -l $REGION/$REGION.fasta $REGION/$REGION.qual $REGION/$REGION.oligos ../analysis/$REGION
done
cd ../analysis

wget http://www.mothur.org/w/images/9/98/Silva.bacteria.zip
unzip Silva.bacteria.zip 
mv silva.bacteria/silva.bacteria.fasta ./
```

To recap, the pipeline consists of removing any fragment that has more than one mismatch to the barcodes or primers, contains an ambiguous basecall, has an average quality score below 60, has a homopolymer longer than 8 nt, and does not align correctly to the region of interest.  

  
  
##Analysis of different communities based on new pipeline
Let's run this using trim.seqs in mothur on each of the files. While we're at it, we'll go ahead and unique, align the sequences, and summarize the alignments.

```{r engine='bash'}
for REGION in v*
do
    cd $REGION
    mothur "#trim.seqs(fasta=$REGION.fasta, qfile=$REGION.qual, oligos=$REGION.oligos, checkorient=T, tdiffs=1, maxambig=0, maxhomop=8, qaverage=60, processors=8);
            unique.seqs(fasta=current); align.seqs(fasta=current, reference=../silva.bacteria.fasta);
            summary.seqs(name=current)"
    cd ../
done
```

Looking at the output from the summary.seqs commands we come up with the following positions within the alignment for our start and end values:


| Region | Start | End   | 
|------------------------- 
| v13    | 1044  | 13125 |  
| v15    | 1044  | 27659 |  
| v16    | 1044  | 34113 |  
| v19    | 1044  | 43116 |  
| v4     | 6428  | 27659 |  
| v35    | 13862 | 23444 |  

Now we want to run screen.seqs to remove sequences that do not start at or before the start position or end at or after end.

```{r engine='bash'}
mothur "#screen.seqs(fasta=v13.trim.unique.align, name=v13.trim.names, group=v13.groups, start=1044, end=13125, processors=8, inputdir=./v13)"
mothur "#screen.seqs(fasta=v15.trim.unique.align, name=v15.trim.names, group=v15.groups, start=1044, end=27659, processors=8, inputdir=./v15)"
mothur "#screen.seqs(fasta=v16.trim.unique.align, name=v16.trim.names, group=v16.groups, start=1044, end=34113, processors=8, inputdir=./v16)"
mothur "#screen.seqs(fasta=v19.trim.unique.align, name=v19.trim.names, group=v19.groups, start=1044, end=43116, processors=8, inputdir=./v19)"
mothur "#screen.seqs(fasta=v35.trim.unique.align, name=v35.trim.names, group=v35.groups, start=6428, end=27659, processors=8, inputdir=./v35)"
mothur "#screen.seqs(fasta=v4.trim.unique.align, name=v4.trim.names, group=v4.groups, start=13862, end=23444, processors=8, inputdir=./v4)"
```

After we run screen.seqs, we'll go ahead and complete the pipeline by using filter.seqs to remove any columns that only contain gaps (vertical=T) or that contain missing data (trump=.) and we'll run unique.seqs and summary.seqs to get the sequence lengths:

```{r engine='bash'}
for REGION in v*
do
    mothur "#set.dir(input=./$REGION, output=./$REGION);
            filter.seqs(fasta=$REGION.trim.unique.good.align-../HMP_MOCK.align, vertical=T, trump=., processors=8);
            unique.seqs(fasta=$REGION.trim.unique.good.filter.fasta, name=$REGION.trim.good.names);
            summary.seqs(name=current)"
done
```

Next we'll want to run pre.cluster using the diffs parameter equal to 1 difference per 100 bp. In the previous step we got those lengths:

| Region | Length | diffs |
|--------|--------|-------|
| v13    | 489    |  4    |
| v15    | 879    |  8    |
| v16    | 1028   | 10    |
| v19    | 1458   | 14    | 
| v35    | 545    |  5    |
| v4     | 253    |  2    |

Once we run pre.cluster, we'll check for chimeras, remove them, cluster the sequences and then make a shared file from them

```{r engine='bash'}
mothur "#pre.cluster(fasta=v13/v13.trim.unique.good.filter.unique.fasta, name=v13/v13.trim.unique.good.filter.names, group=v13/v13.good.groups, diffs=4, processors=8);"
mothur "#pre.cluster(fasta=v15/v15.trim.unique.good.filter.unique.fasta, name=v15/v15.trim.unique.good.filter.names, group=v15/v15.good.groups, diffs=10, processors=8);"
mothur "#pre.cluster(fasta=v16/v16.trim.unique.good.filter.unique.fasta, name=v16/v16.trim.unique.good.filter.names, group=v16/v16.good.groups, diffs=10, processors=8);"
mothur "#pre.cluster(fasta=v19/v19.trim.unique.good.filter.unique.fasta, name=v19/v19.trim.unique.good.filter.names, group=v19/v19.good.groups, diffs=14, processors=8);"
mothur "#pre.cluster(fasta=v35/v35.trim.unique.good.filter.unique.fasta, name=v35/v35.trim.unique.good.filter.names, group=v35/v35.good.groups, diffs=5, processors=8);"
mothur "#pre.cluster(fasta=v4/v4.trim.unique.good.filter.unique.fasta, name=v4/v4.trim.unique.good.filter.names, group=v4/v4.good.groups, diffs=2, processors=8);"


for REGION in v*
do
    mothur "#set.dir(input=./$REGION, output=./$REGION);
      chimera.uchime(fasta=$REGION.trim.unique.good.filter.unique.precluster.fasta, name=$REGION.trim.unique.good.filter.unique.precluster.names, group=$REGION.good.groups, dereplicate=T, processors=8);
      remove.seqs(fasta=current, group=current, name=current, accnos=current, dups=F);
      dist.seqs(fasta=current, cutoff=0.15, processors=8);
      cluster();
      make.shared(list=current, label=0.03, group=current)"
done
```


Let's get the error rates for our mock communities from before and after running the pre.cluster steps.

```{r engine='bash'}

for REGION in v*
do
    for REP in 1 2 3
    do
        mothur "#set.dir(input=./$REGION, output=./$REGION);
            get.groups(fasta=$REGION.trim.unique.good.filter.unique.fasta, group=$REGION.good.pick.groups, name=$REGION.trim.unique.good.filter.names, groups=mock$REP.$REGION);
            system(mv $REGION/$REGION.trim.unique.good.filter.pick.names $REGION/$REGION.mock$REP.unique.names);
            system(mv $REGION/$REGION.trim.unique.good.filter.unique.pick.fasta $REGION/$REGION.mock$REP.unique.fasta);
            seq.error(fasta=$REGION.mock$REP.unique.fasta, name=$REGION.mock$REP.unique.names, reference=HMP_MOCK.filter.fasta, aligned=T, processors=8)"            

        mothur "#set.dir(input=./$REGION, output=./$REGION);
            get.groups(fasta=$REGION.trim.unique.good.filter.unique.precluster.pick.fasta, group=$REGION.good.pick.groups, name=$REGION.trim.unique.good.filter.unique.precluster.pick.names, groups=mock$REP.$REGION);
            system(mv $REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.pick.names $REGION/$REGION.mock$REP.precluster.names);
            system(mv $REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.pick.fasta $REGION/$REGION.mock$REP.precluster.fasta);
            seq.error(fasta=$REGION.mock$REP.precluster.fasta, name=$REGION.mock$REP.precluster.names, reference=HMP_MOCK.filter.fasta, aligned=T, processors=8)"
    done
done
```

Let's see what the error rates were:

```{r}
summarizeError <- function(folder, method){
  file1 <- paste(folder, "/", folder, ".mock1.", method, ".error.summary", sep="")
  file2 <- paste(folder, "/", folder, ".mock2.", method, ".error.summary", sep="")
  file3 <- paste(folder, "/", folder, ".mock3.", method, ".error.summary", sep="")
  
  summary <- rbind(read.table(file=file1, header=T, row.names=1), read.table(file=file2, header=T, row.names=1), read.table(file=file3, header=T, row.names=1))
  nochim <- summary[summary$numparents==1,]
  error <- sum(nochim$weight * nochim$mismatches) / sum(nochim$weight * nochim$total)
  return(error)
}

regions <- dir(path="./", pattern="v\\d+")

unique <- unlist(lapply(regions, summarizeError, "unique"))
precluster <- unlist(lapply(regions, summarizeError, "precluster"))
error <- cbind(unique, precluster)
rownames(error) <- regions

#         unique  precluster
#v4  0.001746057 0.000943217
#v35 0.009064385 0.007661003
#v13 0.008320245 0.007029193
#v15 0.003644766 0.001727743
#v16 0.006742346 0.005426787
#v19 0.004917835 0.003397170
```

We see that even with applying the preclustering the error rates do not approach what we have previously observed with 454 or MiSeq-generated data.



One of the parameters we'd like to know is the number of OTUs per region and sample. To do this, we will need to rarefy our data to a common number of sequences. Let's count the number of reads across all samples:

```{r}
regions <- dir(path="./", pattern="^v\\d+")

counts <- matrix(rep(0, length(regions)*12), nrow=length(regions))
rownames(counts) <- regions
colnames(counts) <- c("human1", "human2", "human3", "mock1", "mock2", "mock3", "mouse1", "mouse2", "mouse3", "soil1", "soil2", "soil3")


for(r in regions){
  shared <- read.table(file=paste(r, "/", r, ".trim.unique.good.filter.unique.precluster.pick.an.shared", sep=""), header=T)
  rownames(shared) <- shared$Group
  shared <- shared[,-c(1,2,3)]
  
  groups <- gsub(".v\\d*", "", rownames(shared))
  stopifnot(sum(groups == colnames(counts)) == length(groups))
  nseqs <- apply(shared, 1, sum)
  counts[r,] <- nseqs
}
```

Unfortunately, those counts are kind of depressing:

|   | human1  | human2	| human3	| mock1		| mock2		| mock3		| mouse1	| mouse2	| mouse3	| soil1		| soil2	| soil3	|
|-----------------------------------------------------------------------------------------------------------------------|
| v13 |  1038 |   810   | 1062   |  750     |  767    |  792    |  546    | 1049    |  365    |  790    |   606 |  870  |
| v15 |   556 |   700   | 1398   | 1459     | 1866    | 1669    | 1035    |  671    | 1345    | 1259    |  1480 | 1498  |
| v16 |   492 |   437   |  592   |  270     |  244    |  247    |  262    |  448    |  286    |  358    |   299 |  210  |
| v19 |   165 |    55   |  134   |  455     |  402    |  357    |  314    |  109    |  117    |  399    |   479 |  710  |
| v35 |  1050 |   965   |  848   |  979     | 1247    | 1231    |  634    |  606    |  425    |  612    |   357 | 1075  |
| v4  |   620 |   908   |  572   | 3721     | 4101    | 4857    | 1527    |  979    | 1186    |  728    |  2707 | 1310  |

Let's merge the three replicates for each sample like we did for the error analysis and move forward... First we'll make a mapping file and then we'll run merge.groups in mothur

```{r}
regions <- dir(path="./", pattern="v\\d+")
for(r in regions){
  write.table(cbind(paste(colnames(counts), ".", r, sep=""), gsub("\\d", "", colnames(counts))), file=paste(r, "/merge.groups", sep=""), quote=F, row.names=F, col.names=F, sep="\t")
}
```

```{r engine='bash'}
for REGION in v*
do
    mothur "#merge.groups(shared=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.an.shared, design=$REGION/merge.groups)"
done
```

Here's what we get out when we run the above code again on the meged groups:


```{r}

regions <- dir(path="./", pattern="v\\d+")

counts <- matrix(rep(0, length(regions)*4), nrow=length(regions))
rownames(counts) <- regions
colnames(counts) <- c("human", "mock","mouse", "soil")

for(r in regions){
  shared <- read.table(file=paste(r, "/", r, ".trim.unique.good.filter.unique.precluster.pick.an.merge.shared", sep=""), header=T)
  rownames(shared) <- shared$Group
  shared <- shared[,-c(1,2,3)]
  
  groups <- gsub(".v\\d*", "", rownames(shared))
  stopifnot(sum(groups == colnames(counts)) == length(groups))
  nseqs <- apply(shared, 1, sum)
  counts[r,] <- nseqs
}
```

The merged counts:

|     | human | mock   | mouse | soil
|-------------------------------------
| v13 | 2910  |  2309  | 1960  | 2266
| v15 | 2654  |  4994  | 3051  | 4237
| v16 | 1521  |   761  |  996  |  867
| v19 |  354  |  1214  |  540  | 1588
| v35 | 2863  |  3457  | 1665  | 2044
| v4  | 2100  | 12679  | 3692  | 4745

Let's rarefy everything to 354 reads per sample

```{r engine="bash"}
for REGION in v*
do
    mothur "#summary.single(shared=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.an.merge.shared, calc=sobs-coverage, subsample=354, iters=1000)"
done
```

Let's remove all of the chimeras we didn't detect and see how many OTUs we would have come up with

```{r engine='bash'}
for REGION in v*
do
  grep "2$" $REGION/$REGION.mock*error.summary | cut -f 2 -d ":" | cut -f 1 > $REGION/$REGION.extra.chimeras
  cat $REGION/$REGION.mock?.precluster.fasta > $REGION/$REGION.mock.precluster.fasta
  cat $REGION/$REGION.mock?.precluster.names > $REGION/$REGION.mock.precluster.names
  mothur "#remove.seqs(fasta=$REGION/$REGION.mock.precluster.fasta, name=$REGION/$REGION.mock.precluster.names, accnos=$REGION/$REGION.extra.chimeras);
          dist.seqs(cutoff=0.15); cluster(); summary.single(subsample=283, calc=sobs, label=0.03)"
done
```

Let's use the reference sequences we sampled to see what the "correct" number of OTUs would have been

```{r engine='bash'}
for REGION in v*
do
    grep "1$" $REGION/$REGION.mock*error.summary | cut -f 2 | sort | uniq > $REGION/mock.ref.accnos
    mothur "#get.seqs(fasta=$REGION/HMP_MOCK.filter.fasta, accnos=$REGION/mock.ref.accnos); dist.seqs(cutoff=0.15, output=lt); cluster(phylip=current); summary.single(label=0.03, calc=sobs)"
done
```

Now we want to summarize the number of OTUs we observed under different conditions:

```{r}
getOTUCounts <- function(region){
  perfect <- read.table(file=paste0(region, "/HMP_MOCK.filter.pick.phylip.an.summary"), header=T)
  nochims <- read.table(file=paste0(region, "/", region, ".mock.precluster.pick.an.ave-std.summary"), header=T)
  observed <- read.table(file=paste0(region, "/", region, ".trim.unique.good.filter.unique.precluster.pick.an.merge.groups.ave-std.summary"), header=T)
  return(c(perfect[1L,2], nochims[1,3], observed[2,4], observed[4,4], observed[3,4], observed[1,4]))
}

regions <- dir(path="./", pattern="v\\d+")

otu.table <- t(sapply(regions, getOTUCounts))
colnames(otu.table) <- c("perfect", "no.chims", "obs.mock", "soil", "mouse", "human")

# v13      20   35.937   55.401 305.985 122.231 88.773
# v15      20   27.474   28.714 285.448  64.535 62.028
# v16      20   40.322   69.514 306.604 117.886 80.746
# v19      20   25.501   35.292 279.116  73.578 83.000
# v35      20   57.477   76.115 279.711 177.080 72.076
# v4       19   21.007   22.385 245.987  57.993 47.201
```


Now we'd like to go ahead and classify all of our sequences using the RDP, greengenes, and SILVA training sets:

```{r engine='bash'}
wget -N http://www.mothur.org/w/images/5/59/Trainset9_032012.pds.zip
unzip -o Trainset9_032012.pds.zip
mv trainset9_032012.pds.tax trainset9_032012.pds_rdp.tax

wget -N http://www.mothur.org/w/images/6/68/Gg_13_8_99.taxonomy.tgz
tar xvzf Gg_13_8_99.taxonomy.tgz
mv gg_13_8_99.gg.tax gg_13_8_99.pds_gg.tax

wget -N http://www.mothur.org/w/images/2/27/Silva.nr_v119.tgz
tar xvzf Silva.nr_v119.tgz
mothur "#degap.seqs(fasta=silva.nr_v119.align)"

for REGION in v*
do
  mothur "#classify.seqs(fasta=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.fasta, reference=trainset9_032012.pds.fasta, taxonomy=trainset9_032012.pds_rdp.tax, processors=8);
			    classify.seqs(fasta=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.fasta, reference=gg_13_8_99.fasta, taxonomy=gg_13_8_99.pds_gg.tax, processors=8);
          classify.seqs(fasta=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.fasta, reference=silva.nr_v119.ng.fasta, taxonomy=silva.nr_v119.tax, processors=8)"
done
```

Let's also classify the sequences from the mock community samples that we pulled out earlier:

```{r engine='bash'}
for REGION in v*
do
  cat $REGION/$REGION.mock?.precluster.fasta > $REGION/$REGION.mock.precluster.fasta
  mothur "#classify.seqs(fasta=$REGION/$REGION.mock.precluster.fasta-$REGION/HMP_MOCK.filter.fasta, reference=trainset9_032012.pds.fasta, taxonomy=trainset9_032012.pds_rdp.tax, processors=8);
	         classify.seqs(fasta=$REGION/$REGION.mock.precluster.fasta, reference=gg_13_8_99.fasta, taxonomy=gg_13_8_99.pds_gg.tax, processors=8)"
done

```
        
Let's see what fraction of each dataset classifies to each taxonomic level by both classification databases

```{r}
countGoodBootstraps <- function(nameConf, cutoff=80){
  bootstrap <- gsub(".*\\((\\d*)\\).*", "\\1", nameConf)
  bootstrap[bootstrap == "unclassified"] = 0
  return(sum(as.numeric(bootstrap) >= cutoff))
}


getDepths <- function(taxFileName, cutoff=80){
  tax <- scan(taxFileName, what="", quiet =T)
  lines <- 1:length(tax)
  seqNames <- tax[lines %% 2 == 1]
  taxString <- tax[lines %% 2 == 0]
  taxList <- strsplit(taxString, ";")
  depths <- unlist(lapply(taxList, countGoodBootstraps))
  names(depths) <- seqNames
  return(depths)
}

regions <- dir(path="./", pattern="v\\d+")

for(r in regions){
  rdpFileName <- paste(r, "/", r, ".trim.unique.good.filter.unique.precluster.pick.pds_rdp.wang.taxonomy", sep="")
  rdp <- getDepths(rdpFileName)

  ggFileName <- paste(r, "/", r, ".trim.unique.good.filter.unique.precluster.pick.pds_gg.wang.taxonomy", sep="")
  gg <- getDepths(ggFileName)
  write.table(cbind("rdp" = rdp, "gg" = gg), file=paste(r, "/", r, ".tax.compare", sep=""), quote=F)
  
  
  rdpMock <- paste(r, "/", r, ".mock.precluster.pds_rdp.wang.taxonomy", sep="")
  rdp <- getDepths(rdpMock)

  ggMock <- paste(r, "/", r, ".mock.precluster.pds_gg.wang.taxonomy", sep="")
  gg <- getDepths(ggMock)
  write.table(cbind("rdp" = rdp, "gg" = gg), file=paste(r, "/mock.tax.compare", sep=""), quote=F)  
}
```

Now we'd like to break this down by sample type. First we'll count the number of times each sequence shows up in each group using mothur:

```{r engine='bash'}
for REGION in v*
do
    mothur "#merge.groups(group=$REGION/$REGION.good.pick.groups, design=$REGION/merge.groups);
            count.seqs(group=$REGION/$REGION.good.pick.merge.groups, name=$REGION/$REGION.trim.unique.good.filter.unique.precluster.pick.names)"
done
```

```{r}

getDepthByLibrary <- function(region){
  count.file <- paste(region, "/", region, ".trim.unique.good.filter.unique.precluster.pick.count_table", sep="")
  count.table <- read.table(file=count.file, header=T, row.names=1)
  
  depth.file <- paste(region, "/", region, ".tax.compare", sep="")
  depth.table <- read.table(file=depth.file, header=T, row.names=1)
  depth.table$rdp <- factor(depth.table$rdp, levels=0:7)
  depth.table$gg <- factor(depth.table$gg, levels=0:7)
  
  mock.depth <- depth.table[count.table$mock > 0,]
  human.depth <- depth.table[count.table$human > 0,]
  mouse.depth <- depth.table[count.table$mouse > 0,]
  soil.depth <- depth.table[count.table$soil > 0,]
  
  mock.gg <- 100*summary(mock.depth$gg)/nrow(mock.depth)
  human.gg <- 100*summary(human.depth$gg)/nrow(human.depth)
  mouse.gg <- 100*summary(mouse.depth$gg)/nrow(mouse.depth)
  soil.gg <- 100*summary(soil.depth$gg)/nrow(soil.depth)
  
  mock.rdp <- 100*summary(mock.depth$rdp)/nrow(mock.depth)
  human.rdp <- 100*summary(human.depth$rdp)/nrow(human.depth)
  mouse.rdp <- 100*summary(mouse.depth$rdp)/nrow(mouse.depth)
  soil.rdp <- 100*summary(soil.depth$rdp)/nrow(soil.depth)
  
  return(rbind(mock.rdp, human.rdp, mouse.rdp, soil.rdp, mock.gg, human.gg, mouse.gg, soil.gg))
}

#composite <-array(0, dim=c(8,6,8))
composite <- data.frame(matrix(rep(0, 8*6*8), ncol=8))
colnames(composite) <- 0:7
composite[1:8,] <- getDepthByLibrary("v4");
composite[9:16,] <- getDepthByLibrary("v35")
composite[17:24,] <- getDepthByLibrary("v13")
composite[25:32,] <- getDepthByLibrary("v15")
composite[33:40,] <- getDepthByLibrary("v16")
composite[41:48,] <- getDepthByLibrary("v19")

composite$region <- c(rep("v4", 8), rep("v35", 8), rep("v13", 8), rep("v15", 8), rep("v16", 8), rep("v19", 8))
composite$database <- rep(c(rep("rdp", 4), rep("gg", 4)), 6)
composite$sample <- rep(c("mock", "human", "mouse", "soil"), 12)
composite$total <- composite[,"6"] + composite[,"7"]
write.table(file="taxonomy.depth.analysis", composite, quote=F)
```

Let's build some dot-plots to show how well the various regions classified for each sample

```{r}
  data <- read.table(file="taxonomy.depth.analysis", header=T)
  rdp <- cbind("Mock"=data[data$database=="rdp" & data$sample=="mock", "total"], "Human"=data[data$database=="rdp" & data$sample=="human", "total"],
               "Mouse"=data[data$database=="rdp" & data$sample=="mouse", "total"], "Soil"=data[data$database=="rdp" & data$sample=="soil", "total"])
  rownames(rdp) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

  gg <- cbind("Mock"=data[data$database=="gg" & data$sample=="mock", "total"], "Human"=data[data$database=="gg" & data$sample=="human", "total"],
               "Mouse"=data[data$database=="gg" & data$sample=="mouse", "total"], "Soil"=data[data$database=="gg" & data$sample=="soil", "total"])
  rownames(gg) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

  gg.sp <- cbind("Mock"=data[data$database=="gg" & data$sample=="mock", "X7"], "Human"=data[data$database=="gg" & data$sample=="human", "X7"],
               "Mouse"=data[data$database=="gg" & data$sample=="mouse", "X7"], "Soil"=data[data$database=="gg" & data$sample=="soil", "X7"])
  rownames(gg.sp) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

  par(mar=c(5, 5, 0.5, 1))
  dotchart(rdp, xlim=c(0,100), col="black", xlab="Unique reads that classified\nto genus or species level (%)")
  points(x=gg[,"Mock"], y=25:30, pch=19, col="black")
  points(x=gg[,"Human"], y=22:17, pch=19, col="black")
  points(x=gg[,"Mouse"], y=14:9, pch=19, col="black")
  points(x=gg[,"Soil"], y=6:1, pch=19, col="black")

  points(x=gg.sp[,"Mock"], y=25:30, pch=21, bg="gray")
  points(x=gg.sp[,"Human"], y=22:17, pch=21, bg="gray")
  points(x=gg.sp[,"Mouse"], y=14:9, pch=21, bg="gray")
  points(x=gg.sp[,"Soil"], y=6:1, pch=21, bg="gray")

  legend(x=63, y=12, legend=c("RDP (gen.)", "greengenes (gen.+sp.)", "greengenes (sp.)"), pch=c(21,19,21), col=c("black", "black", "black"), pt.bg=c("white", "black", "gray"), bg="white")
```